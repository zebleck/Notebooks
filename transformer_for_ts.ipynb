{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a transformer for time-series forecasting\n",
    "\n",
    "https://towardsdatascience.com/how-to-make-a-pytorch-transformer-for-time-series-forecasting-69e073d4061e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import math\n",
    "from torch import nn, Tensor\n",
    "\n",
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dropout: float=0.1,\n",
    "                 max_seq_len: int=5000,\n",
    "                 d_model: int=512,\n",
    "                 batch_first: bool=False):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.batch_first = batch_first\n",
    "        self.x_dim = 1 if batch_first else 0\n",
    "\n",
    "        position = torch.arange(max_seq_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_seq_len, 1, d_model)\n",
    "\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x + self.pe[:x.size(self.x_dim)]\n",
    "\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TimeSeriesTransformer:\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 dim_val,\n",
    "                 dropout_pos_enc,\n",
    "                 max_seq_len,\n",
    "                 n_heads):\n",
    "        self.encoder_input_layer = nn.Linear(\n",
    "            in_features=input_size,\n",
    "            out_features=dim_val\n",
    "        )\n",
    "\n",
    "        self.positional_encoding_layer = PositionalEncoder(\n",
    "            d_model=dim_val,\n",
    "            dropout=dropout_pos_enc,\n",
    "            max_seq_len=max_seq_len\n",
    "        )\n",
    "\n",
    "        encoder_layer = torch.nn.TransformerEncoderLayer(\n",
    "            d_model=dim_val,\n",
    "            nhead=n_heads,\n",
    "            batch_first=True)\n",
    "        self.encoder = torch.nn.TransformerEncoder(encoder_layer, num_layers=4, norm=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
