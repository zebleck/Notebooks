{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import requests\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "with os.add_dll_directory('C://openslide-win64/bin'):\n",
    "\timport openslide\n",
    "\n",
    "# Read the CSV file\n",
    "data_file = 'annotation.csv'\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "diagnosis_counts = df['diagnosis'].value_counts()\n",
    "\n",
    "diagnosis_labels = df['diagnosis'].fillna('nan').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_with_min_size(file_path, min_size=2048):\n",
    "\n",
    "\tndpi_file = openslide.OpenSlide(file_path)\n",
    "\tndpi_metadata = dict(ndpi_file.properties)\n",
    "\n",
    "\t# Get the number of magnification levels in the NDPI file\n",
    "\tmag_level_count = int(ndpi_metadata['openslide.level-count']) - 1\n",
    "\ttarget_mag_level = mag_level_count\n",
    "\twhile target_mag_level >= 0:\n",
    "\t\t# Get the width and height of the requested magnification level\n",
    "\t\ttarget_ndpi_width = int(ndpi_metadata[f'openslide.level[{target_mag_level}].width'])\n",
    "\t\ttarget_ndpi_height = int(ndpi_metadata[f'openslide.level[{target_mag_level}].height'])\n",
    "\t\tif target_ndpi_width >= min_size and target_ndpi_height >= min_size:\n",
    "\t\t\tbreak\n",
    "\t\ttarget_mag_level -= 1\n",
    "\tif target_mag_level < 0:\n",
    "\t\tprint('Error: NDPI file is too small')\n",
    "\t\treturn None, ndpi_metadata\n",
    "\n",
    "\ttarget_ndpi_width = int(ndpi_metadata[f'openslide.level[{target_mag_level}].width'])\n",
    "\ttarget_ndpi_height = int(ndpi_metadata[f'openslide.level[{target_mag_level}].height'])\n",
    "\n",
    "\t# Sometimes there are error reading the JPEG files so we try at different mag levels and downsample\n",
    "\n",
    "\tmag_level = target_mag_level\n",
    "\twhile mag_level >= 0:\n",
    "\t\t# Open the NDPI file using OpenSlide\n",
    "\t\tif mag_level < target_mag_level:\n",
    "\t\t\tndpi_file = openslide.OpenSlide(file_path)\n",
    "\n",
    "\t\t# Get the width and height of the requested magnification level\n",
    "\t\tndpi_width = int(ndpi_metadata[f'openslide.level[{mag_level}].width'])\n",
    "\t\tndpi_height = int(ndpi_metadata[f'openslide.level[{mag_level}].height'])\n",
    "\t\ttry:\n",
    "            # Load the image at the requested magnification level\n",
    "\t\t\tndpi_image = ndpi_file.read_region((0, 0), mag_level, (ndpi_width, ndpi_height))\n",
    "\n",
    "            # Convert the image to RGB format\n",
    "\t\t\tndpi_image = ndpi_image.convert('RGB')\n",
    "\t\t\tif mag_level < target_mag_level:\n",
    "\t\t\t\tndpi_image = ndpi_image.resize((target_ndpi_width, target_ndpi_height))\n",
    "\n",
    "            # Close the NDPI file and return the image\n",
    "\t\t\tndpi_file.close()\n",
    "\t\t\treturn ndpi_image, ndpi_metadata\n",
    "\t\texcept:\n",
    "\t\t\tprint('Trying again with mag', mag_level - 1)\n",
    "\t\t\tmag_level -= 1\n",
    "\t\t\tndpi_file.close()\n",
    "\t\n",
    "\tprint(f'Error: Could not load image from {file_path} at any magnification level')\n",
    "\n",
    "def save_image(processed_path, ndpi_file_name):\n",
    "\tfile_path = os.path.join(processed_path, ndpi_file_name)\n",
    "\toutput_image_path = file_path[:-5] + '.png'\n",
    "\n",
    "\tndpi_image, metadata = get_image_with_min_size(file_path)\n",
    "\n",
    "\t# Save the image\n",
    "\ttry:\n",
    "\t\tndpi_image.save(output_image_path)\n",
    "\texcept:\n",
    "\t\tprint(f'Didn\\'t save {output_image_path}')\n",
    "\n",
    "    # Save the metadata as a JSON file\n",
    "\tmetadata_path = os.path.join(processed_path, 'metadata')\n",
    "\tif not os.path.exists(metadata_path):\n",
    "\t\tos.mkdir(metadata_path)\n",
    "\twith open(os.path.join(os.path.join(processed_path, 'metadata'), ndpi_file_name[:-5] + '.json'), 'w') as metadata_file:\n",
    "\t\tjson.dump(metadata, metadata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing: 2042\n",
      "Non-matching labels:\n",
      "Adamantinomatous craniopharyngioma: 65 85\n",
      "Angiomatous meningioma: 31 32\n",
      "Myxopapillary ependymoma: 22 23\n",
      "Haemangioblastoma: 19 88\n",
      "Pilomyxoid astrocytoma: 18 24\n",
      "Anaplastic oligodendroglioma, IDH-mutant and 1p/19q codeleted: 17 91\n",
      "Diffuse astrocytoma, IDH-wildtype: 17 19\n",
      "Meningothelial meningioma: 16 104\n",
      "Chondrosarcoma: 15 21\n",
      "Giant cell glioblastoma: 15 21\n",
      "Germinoma: 15 20\n",
      "Haemangiopericytoma: 13 34\n",
      "Psammomatous meningioma: 12 28\n",
      "Microcystic meningioma: 12 23\n",
      "Dysembryoplastic neuroepithelial tumour: 11 25\n",
      "Atypical meningioma: 10 83\n",
      "Olfactory neuroblastoma: 8 10\n",
      "Osteoma: 8 9\n",
      "Medulloblastoma, non-WNT/non-SHH: 8 32\n",
      "Schwannoma: 7 81\n",
      "Anaplastic astrocytoma, IDH-wildtype: 7 47\n",
      "Gliosarcoma: 7 59\n",
      "Fibrous meningioma: 7 57\n",
      "Desmoplastic infantile astrocytoma and ganglioglioma: 5 11\n",
      "Ganglioglioma: 4 88\n",
      "Anaplastic meningioma: 3 46\n",
      "Cellular schwannoma: 3 25\n",
      "Pilocytic astrocytoma: 3 173\n",
      "Papillary craniopharyngioma: 3 13\n",
      "Neurofibroma: 3 16\n",
      "Chordoid glioma of the third ventricle: 3 4\n",
      "Diffuse astrocytoma, IDH-mutant: 2 70\n",
      "Glioblastoma, IDH-wildtype: 1 474\n",
      "Pleomorphic xanthoastrocytoma: 1 21\n",
      "Paraganglioma: 1 17\n",
      "MALT lymphoma of the dura: 1 5\n",
      "Papillary meningioma: 1 3\n",
      "Pituicytoma: 1 3\n",
      "Transitional meningioma: -1 68\n",
      "Pituitary adenoma: -1 99\n",
      "Oligodendroglioma, IDH-mutant and 1p/19q codeleted: -1 85\n",
      "Medulloblastoma, SHH-activated and TP53-wildtype: -1 9\n",
      "Rhabdoid meningioma: -1 5\n",
      "Subependymoma: -1 24\n",
      "Anaplastic ependymoma: -1 50\n",
      "Choroid plexus papilloma: -1 21\n",
      "Diffuse large B-cell lymphoma of the CNS: -1 59\n",
      "Subependymal giant cell astrocytoma: -1 14\n",
      "Choroid plexus carcinoma: -1 7\n"
     ]
    }
   ],
   "source": [
    "diagnosis_counts = df['diagnosis'].value_counts()\n",
    "\n",
    "diagnosis_labels = df['diagnosis'].fillna('nan').unique()\n",
    "\n",
    "def compare(compare_path):\n",
    "    missing = []\n",
    "    for label in diagnosis_labels:\n",
    "        folder_path = os.path.join(compare_path, label.replace(\"/\", \"-\"))\n",
    "        num_files = len(glob.glob(os.path.join(folder_path, '*.png')))\n",
    "        if os.path.exists(folder_path) and num_files == 0:\n",
    "            shutil.rmtree(folder_path)\n",
    "        if not os.path.exists(folder_path):\n",
    "            missing.append((label, -1))\n",
    "        else:\n",
    "            missing.append((label, num_files))\n",
    "    return missing\n",
    "\n",
    "folder_path = \"C:/Users/Kontor/Github Repos/Notebooks/biomedical/processed\"\n",
    "missing_labels = compare(folder_path)\n",
    "\n",
    "matching_labels = []\n",
    "non_matching_labels = []\n",
    "total_missing = 0\n",
    "\n",
    "for label, num_files in missing_labels:\n",
    "    if label != 'nan':\n",
    "        if num_files == diagnosis_counts[label]:\n",
    "            matching_labels.append((label, num_files))\n",
    "        else:\n",
    "            total_missing += diagnosis_counts[label] - num_files\n",
    "            non_matching_labels.append((label, num_files))\n",
    "\n",
    "matching_labels = sorted(matching_labels, key=lambda x: x[1], reverse=True)\n",
    "non_matching_labels = sorted(non_matching_labels, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#print(\"Matching labels:\")\n",
    "#for label, num_files in matching_labels:\n",
    "#    print(f\"{label}: {num_files}\")\n",
    "#print()\n",
    "print('Total missing:', total_missing)\n",
    "print(\"Non-matching labels:\")\n",
    "for label, num_files in non_matching_labels:\n",
    "    print(f\"{label}: {num_files}\", diagnosis_counts[label])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automate download"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of the dataset is 3948.2021661920003 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://data-proxy.ebrains.eu/api/v1/datasets/8fc108ab-e2b4-406f-8999-60269dc1f994?limit=5000'\n",
    "header = \"Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJfNkZVSHFaSDNIRmVhS0pEZDhXcUx6LWFlZ3kzYXFodVNJZ1RXaTA1U2k0In0.eyJleHAiOjE2ODQzMzI0OTEsImlhdCI6MTY4MzcyODEwMiwiYXV0aF90aW1lIjoxNjgzNzI3NjkxLCJqdGkiOiI4MTE2ZmJhMC1lNmMwLTQxMzMtOWY3Zi0xNmM5NDQxZDIyMzciLCJpc3MiOiJodHRwczovL2lhbS5lYnJhaW5zLmV1L2F1dGgvcmVhbG1zL2hicCIsImF1ZCI6InRlYW0iLCJzdWIiOiI4NTBlNTA2Ni1mNGQwLTRjOGItYmNiYy02ZjM4ZWQzYjIzMjIiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJkYXRhLXByb3h5LWZyb250Iiwibm9uY2UiOiJiYzM0NGYxMS00MDBmLTRiNmUtOTRiOC04MDBkZDcyYWM4MDAiLCJzZXNzaW9uX3N0YXRlIjoiNzNjZmNlMWYtOTQ5MC00OTg4LTlhOTktMjBlZGJkYmFkNjIwIiwiYWNyIjoiMCIsImFsbG93ZWQtb3JpZ2lucyI6WyJodHRwczovL2RhdGEtcHJveHkuZWJyYWlucy5ldSIsImh0dHBzOi8vZGF0YS1wcm94eS1wcGQuZWJyYWlucy5ldSJdLCJzY29wZSI6InByb2ZpbGUgcm9sZXMgZW1haWwgb3BlbmlkIHRlYW0iLCJzaWQiOiI3M2NmY2UxZi05NDkwLTQ5ODgtOWE5OS0yMGVkYmRiYWQ2MjAiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwibmFtZSI6IkZhYmlhbiBLb250b3IiLCJtaXRyZWlkLXN1YiI6IjMxMDM5NiIsInByZWZlcnJlZF91c2VybmFtZSI6ImZrb250b3IiLCJnaXZlbl9uYW1lIjoiRmFiaWFuIiwiZmFtaWx5X25hbWUiOiJLb250b3IiLCJlbWFpbCI6ImYua29udG9yQHN0dWQudW5pLWhlaWRlbGJlcmcuZGUifQ.Fh2l9MKbT3wMxQsOy7afpMWzotylHJnumL_TCl784zXT-7pGMXOAPN5jNuEiGCAhQOoWrs2Jj3TRWnoDb3IJ2ts2cgeC4NdNjYGP4g9PX5ZamFv60B3g6rh_JXqwLzCYHzcP_K4_Z4J3PENKiRMQq-miN_xjjzYXSleCpMR7AEIyKA7amsx1vx2PQ_VXZC3mCX8qoMQFrqwg0HXpNY6a9yj5WbR_cXat65BCcS5Q52bB8tr9EHfZs9RX_fLgt4C-gCvBAfh0QBCaoNV0P4CWPS959SIcCSAUlb8cXqojyMZADLjjw7BVXombxYAURycIMX_84K9wrnWW5L-WGOOM4g\"\n",
    "\n",
    "def request(url, header):\n",
    "\tresponse = requests.get(url, headers={'Authorization': header})\n",
    "\tif response.status_code == 200:\n",
    "\t\treturn response.json()\n",
    "\telse:\n",
    "\t\tprint(response.json())\n",
    "\t\tprint(f'Request failed with status code {response.status_code}')\n",
    "\t\treturn None\n",
    "\t\n",
    "def download(url, filename, header):\n",
    "\t\n",
    "\twith requests.get(url, headers={'Authorization': header}, stream=True) as r:\n",
    "\t\ttotal_size = int(r.headers.get('content-length', 0))\n",
    "\t\tblock_size = 1024 #1 Kibibyte\n",
    "\n",
    "\t\tprogress_bar = tqdm(total=total_size, unit=\"iB\", unit_scale=True)\n",
    "\n",
    "\t\twith open(filename, \"wb\") as f:\n",
    "\t\t\tfor chunk in r.iter_content(block_size):\n",
    "\t\t\t\tprogress_bar.update(len(chunk))\n",
    "\t\t\t\tf.write(chunk)\n",
    "\t\t\n",
    "\t\tprogress_bar.close()\n",
    "\t\tr.close()\n",
    "\t\t\n",
    "\tif total_size != 0 and progress_bar.n != total_size:\n",
    "\t\tprint(\"ERROR, something went wrong\")\n",
    "\t\treturn False\n",
    "\telse:\n",
    "\t\treturn True\n",
    "\n",
    "data = request(url, header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Adamantinomatous craniopharyngioma/a1976886-357f-11eb-b250-001a7dda7111.ndpi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32ma:\\Programs\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32ma:\\Programs\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32ma:\\Programs\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Adamantinomatous craniopharyngioma/a1976886-357f-11eb-b250-001a7dda7111.ndpi'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(png_path):\n\u001b[0;32m     19\u001b[0m \tn_files \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(glob\u001b[39m.\u001b[39mglob(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_folder_path, \u001b[39m'\u001b[39m\u001b[39m*.png\u001b[39m\u001b[39m'\u001b[39m)))\n\u001b[1;32m---> 20\u001b[0m \t\u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mn_files\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mdiagnosis_counts[name]\u001b[39m}\u001b[39;00m\u001b[39m: Starting download of\u001b[39m\u001b[39m'\u001b[39m, name)\n\u001b[0;32m     21\u001b[0m \t\u001b[39mif\u001b[39;00m download(api_base_url \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mv1.0/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m name, file_path, header):\n\u001b[0;32m     22\u001b[0m \t\tsave_image(data_folder_path, file)\n",
      "File \u001b[1;32ma:\\Programs\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32ma:\\Programs\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32ma:\\Programs\\anaconda3\\envs\\ai\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Adamantinomatous craniopharyngioma/a1976886-357f-11eb-b250-001a7dda7111.ndpi'"
     ]
    }
   ],
   "source": [
    "total_downloads = 0\n",
    "\n",
    "api_base_url = 'https://data-proxy.ebrains.eu/api/v1/datasets/8fc108ab-e2b4-406f-8999-60269dc1f994/'\n",
    "\n",
    "for obj in data['objects']:\n",
    "\tname = obj['name'].replace('v1.0/', '')\n",
    "\tname = name.replace('Embryonal tumour with multilayered rosette, C19MC-altered', 'Embryonal tumour with multilayered rosettes, C19MC-altered')\n",
    "\tif name == 'annotation.csv':\n",
    "\t\tcontinue\n",
    "\tlabel, file = name.split('/')\n",
    "\n",
    "\tdata_folder_path = os.path.join(folder_path, label)\n",
    "\tif not os.path.exists(data_folder_path):\n",
    "\t\tos.makedirs(data_folder_path)\n",
    "\n",
    "\tfile_path = os.path.join(data_folder_path, file)\n",
    "\tpng_path = file_path.replace('.ndpi', '.png')\n",
    "\tif not os.path.exists(png_path):\n",
    "\t\tn_files = len(glob.glob(os.path.join(data_folder_path, '*.png')))\n",
    "\t\tprint(f'{n_files+1}/{diagnosis_counts[label]}: Starting download of', name)\n",
    "\t\tif download(api_base_url + 'v1.0/' + name, file_path, header):\n",
    "\t\t\tsave_image(data_folder_path, file)\n",
    "\t\tos.remove(file_path)\n",
    "\t\ttotal_downloads += 1\n",
    "\n",
    "print('Finished downloading', total_downloads, 'files')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deprecated: was used to compare two versions of downloader folders to see which one has more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying again with mag 3\n",
      "Trying again with mag 2\n"
     ]
    },
    {
     "ename": "ArgumentError",
     "evalue": "argument 1: <class 'ValueError'>: Passing closed slide object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 47\u001b[0m, in \u001b[0;36mget_image_with_min_size\u001b[1;34m(file_path, min_size)\u001b[0m\n\u001b[0;32m     46\u001b[0m \tndpi_file\u001b[39m.\u001b[39mclose()\n\u001b[1;32m---> 47\u001b[0m \t\u001b[39mreturn\u001b[39;00m ndpi_image, \u001b[39mdict\u001b[39;49m(ndpi_metadata)\n\u001b[0;32m     48\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "File \u001b[1;32ma:\\Programs\\anaconda3\\envs\\ai\\lib\\_collections_abc.py:720\u001b[0m, in \u001b[0;36mKeysView.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 720\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mapping\n",
      "File \u001b[1;32ma:\\Programs\\anaconda3\\envs\\ai\\lib\\site-packages\\openslide\\__init__.py:264\u001b[0m, in \u001b[0;36m_OpenSlideMap.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 264\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keys())\n",
      "File \u001b[1;32ma:\\Programs\\anaconda3\\envs\\ai\\lib\\site-packages\\openslide\\__init__.py:273\u001b[0m, in \u001b[0;36m_PropertyMap._keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_keys\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 273\u001b[0m     \u001b[39mreturn\u001b[39;00m lowlevel\u001b[39m.\u001b[39;49mget_property_names(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_osr)\n",
      "\u001b[1;31mArgumentError\u001b[0m: argument 1: <class 'ValueError'>: Passing closed slide object",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img \u001b[39m=\u001b[39m get_image_with_min_size(file_path)\n\u001b[0;32m      2\u001b[0m img\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mtest.png\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 51\u001b[0m, in \u001b[0;36mget_image_with_min_size\u001b[1;34m(file_path, min_size)\u001b[0m\n\u001b[0;32m     49\u001b[0m \t\t\u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrying again with mag\u001b[39m\u001b[39m'\u001b[39m, mag_level \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     50\u001b[0m \t\tmag_level \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> 51\u001b[0m \t\tndpi_file\u001b[39m.\u001b[39;49mclose()\n\u001b[0;32m     53\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mError: Could not load image from \u001b[39m\u001b[39m{\u001b[39;00mfile_path\u001b[39m}\u001b[39;00m\u001b[39m at any magnification level\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32ma:\\Programs\\anaconda3\\envs\\ai\\lib\\site-packages\\openslide\\__init__.py:180\u001b[0m, in \u001b[0;36mOpenSlide.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclose\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    179\u001b[0m     \u001b[39m\"\"\"Close the OpenSlide object.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     lowlevel\u001b[39m.\u001b[39;49mclose(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_osr)\n",
      "\u001b[1;31mArgumentError\u001b[0m: argument 1: <class 'ValueError'>: Passing closed slide object"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "img = get_image_with_min_size(file_path)\n",
    "img.save(\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diagnosis_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m path1 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUsers\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mKontor\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mGithub Repos\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mNotebooks\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mbiomedical\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mprocessed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m path2 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUsers\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mKontor\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mGithub Repos\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mNotebooks\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mbiomedical\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 15\u001b[0m missing1, present1 \u001b[39m=\u001b[39m compare(path1)\n\u001b[0;32m     16\u001b[0m missing2, present2 \u001b[39m=\u001b[39m compare(path2)\n\u001b[0;32m     18\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(missing1), missing1)\n",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m, in \u001b[0;36mcompare\u001b[1;34m(compare_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m missing \u001b[39m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m present \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m diagnosis_labels:\n\u001b[0;32m      5\u001b[0m \tfolder_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(compare_path, label)\n\u001b[0;32m      6\u001b[0m \t\u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(folder_path):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'diagnosis_labels' is not defined"
     ]
    }
   ],
   "source": [
    "def compare(compare_path):\n",
    "\tmissing = []\n",
    "\tpresent = []\n",
    "\tfor label in diagnosis_labels:\n",
    "\t\tfolder_path = os.path.join(compare_path, label)\n",
    "\t\tif not os.path.exists(folder_path):\n",
    "\t\t\tmissing.append(label)\n",
    "\t\telse:\n",
    "\t\t\tpresent.append(label)\n",
    "\treturn sorted(missing), sorted(present)\n",
    "\n",
    "path1 = \"C:\\\\Users\\\\Kontor\\\\Github Repos\\\\Notebooks\\\\biomedical\\\\processed\"\n",
    "path2 = \"C:\\\\Users\\\\Kontor\\\\Github Repos\\\\Notebooks\\\\biomedical\\\\data\"\n",
    "\n",
    "missing1, present1 = compare(path1)\n",
    "missing2, present2 = compare(path2)\n",
    "\n",
    "print(len(missing1), missing1)\n",
    "print(len(missing2), missing2)\n",
    "overlapping_labels = sorted(list(set(missing1).intersection(set(missing2))))\n",
    "\n",
    "print(len(overlapping_labels), overlapping_labels)\n",
    "\n",
    "def get_file_overlap(path1, path2):\n",
    "\tfiles1 = [file for file in os.listdir(path1) if file.endswith('.png')]\n",
    "\tfiles2 = [file for file in os.listdir(path2) if file.endswith('.png')]\n",
    "\treturn sorted(list(set(files1).intersection(set(files2)))), sorted(files1), sorted(files2)\n",
    "\n",
    "for folder in os.listdir(path1):\n",
    "\tif folder in present1 and folder in present2:\n",
    "\t\toverlap, files1, files2 = get_file_overlap(os.path.join(path1, folder), os.path.join(path2, folder))\n",
    "\t\tif len(overlap) != len(files1) or len(overlap) != len(files2):\n",
    "\t\t\tprint(folder, len(overlap), len(files1), len(files2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
